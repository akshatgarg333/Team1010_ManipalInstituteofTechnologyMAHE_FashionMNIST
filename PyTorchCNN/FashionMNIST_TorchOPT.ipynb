{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Fashion MNIST using CNN**"
      ],
      "metadata": {
        "id": "tNbaaGyN5cxq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As seen in the previous model using a basic neural network, the accuracy was coming around 88% which is low. The accuracy can be increased using a CNN (Convolutional Neural Network)"
      ],
      "metadata": {
        "id": "F67WcmQ-5HLE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the necessary libraries"
      ],
      "metadata": {
        "id": "w1gtzdcm5nny"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Various libraries for data handling, updation and visualisation\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets,transforms\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "_YmKCHjM5b4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fa2af81-d19c-4cc3-c760-4fcd4e23d4c2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7efdfed06990>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the data"
      ],
      "metadata": {
        "id": "jP6LkeTS7ujk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Using torch to load the data\n",
        "#Adding transforms\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "train_images = torchvision.datasets.FashionMNIST(\n",
        "    root = './data/FashionMNIST',\n",
        "    train = True,\n",
        "    download = True,\n",
        "    transform =transform\n",
        ")\n",
        "test_images = torchvision.datasets.FashionMNIST(\n",
        "    root = './data/FashionMNIST',\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = transform\n",
        ")\n",
        "train_labels = train_images.targets\n",
        "test_labels=test_images.targets\n",
        "train_loader = torch.utils.data.DataLoader(train_images, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_images, batch_size=64, shuffle=False)"
      ],
      "metadata": {
        "id": "zI-vHVyK5rn4"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Storing the labels\n",
        "labels = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n"
      ],
      "metadata": {
        "id": "yb1FlwSbB3-U"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Exploring the data"
      ],
      "metadata": {
        "id": "7AjxnVdM7zjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to explore data\n",
        "def FMNIST_data_info(train_images, test_images):\n",
        "    print(\"Train images length:\", len(train_images))\n",
        "    image, label = train_images[0]\n",
        "    print(\"Image shape:\", image.shape)\n",
        "    print(\"Test images length:\", len(test_images))\n",
        "    image, label = test_images[0]\n",
        "    print(\"Image shape:\", image.shape)"
      ],
      "metadata": {
        "id": "-75ymHSj7w_3"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Calling the function to see data info\n",
        "FMNIST_data_info(train_images, test_images)"
      ],
      "metadata": {
        "id": "CX38hxut71wX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ca0e5c0-b73e-44ee-cf1c-64d608b5b619"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train images length: 60000\n",
            "Image shape: torch.Size([1, 28, 28])\n",
            "Test images length: 10000\n",
            "Image shape: torch.Size([1, 28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From above, the training set is of 60000 images having 28X28 dimension and test set is of 10000 images having 28X28 dimension"
      ],
      "metadata": {
        "id": "zei_okcP7-as"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing of data"
      ],
      "metadata": {
        "id": "HwIR47fm8Jia"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Function for checking for null values of labels in test and train dataset as they can hamper with the results and cause redundancy\n",
        "def count_null_values(labels):\n",
        "    null_values = np.isnan(labels).sum()\n",
        "    print(\"Null values:\", null_values)"
      ],
      "metadata": {
        "id": "lIS2xJ7r8FUP"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Null values in Train_Labels\n",
        "print(\"Null values in train_labels:\")\n",
        "count_null_values(train_labels)\n",
        "\n",
        "#Null values in Test_Labels\n",
        "print(\"Null values in test_labels:\")\n",
        "count_null_values(test_labels)"
      ],
      "metadata": {
        "id": "-OBQ-E406agG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba1e6b7-b14f-432d-cda9-393da0bfcc48"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Null values in train_labels:\n",
            "Null values: tensor(0)\n",
            "Null values in test_labels:\n",
            "Null values: tensor(0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Since there are no null values, we can carry on with the model"
      ],
      "metadata": {
        "id": "qAEyVvRA8L2j"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Building the model\n"
      ],
      "metadata": {
        "id": "HkqcUtQO8Vp0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating the model\n",
        "\n",
        "class CNNModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNModel, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu1 = nn.ReLU()\n",
        "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
        "        self.maxpool1 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.dropout1 = nn.Dropout(0.3)\n",
        "\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu2 = nn.ReLU()\n",
        "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
        "        self.maxpool2 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.dropout2 = nn.Dropout(0.3)\n",
        "\n",
        "\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
        "        self.relu3 = nn.ReLU()\n",
        "        self.batchnorm3 = nn.BatchNorm2d(128)\n",
        "        self.maxpool3 = nn.MaxPool2d(kernel_size=2)\n",
        "        self.dropout3 = nn.Dropout(0.25)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "\n",
        "        self.fc1 = nn.Linear(128 * 3 * 3, 256)\n",
        "        self.relu4 = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc2 = nn.Linear(256, 64)\n",
        "        self.relu5 = nn.ReLU()\n",
        "        self.dropout2 = nn.Dropout(0.5)\n",
        "\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.relu1(x)\n",
        "        x = self.maxpool1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.relu2(x)\n",
        "        x = self.maxpool2(x)\n",
        "\n",
        "        x = self.conv3(x)\n",
        "        x = self.relu3(x)\n",
        "        x = self.maxpool3(x)\n",
        "\n",
        "        x = self.flatten(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu4(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu5(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = self.fc3(x)\n",
        "        x = self.softmax(x)\n",
        "\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "F5gBT2FLB6jB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Creating an instance\n",
        "model=CNNModel()\n",
        "device = torch.device(\"cpu\")\n",
        "model.to(device)"
      ],
      "metadata": {
        "id": "JZyf-bV3BN-2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f751b654-da79-4d07-fbbf-8891c92fe9bc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNNModel(\n",
              "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu1): ReLU()\n",
              "  (batchnorm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (maxpool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (dropout1): Dropout(p=0.5, inplace=False)\n",
              "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu2): ReLU()\n",
              "  (batchnorm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (maxpool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (dropout2): Dropout(p=0.5, inplace=False)\n",
              "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (relu3): ReLU()\n",
              "  (batchnorm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (maxpool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  (dropout3): Dropout(p=0.25, inplace=False)\n",
              "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
              "  (fc1): Linear(in_features=1152, out_features=256, bias=True)\n",
              "  (relu4): ReLU()\n",
              "  (fc2): Linear(in_features=256, out_features=64, bias=True)\n",
              "  (relu5): ReLU()\n",
              "  (fc3): Linear(in_features=64, out_features=10, bias=True)\n",
              "  (softmax): Softmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define the optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "T0njhB_ECDTb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "\n",
        "        # Update the parameters\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "        # Compute training statistics\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        train_correct += (predicted == labels).sum().item()\n",
        "        total_samples += labels.size(0)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    # Compute epoch statistics\n",
        "    train_accuracy = 100 * train_correct / total_samples\n",
        "    train_loss /= len(train_loader)\n",
        "\n",
        "    # Print epoch results\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
        "          f\"Train Loss: {train_loss:.4f}, \"\n",
        "          f\"Train Accuracy: {train_accuracy:.2f}%\")"
      ],
      "metadata": {
        "id": "8J25woZICWeJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6fe6032-8b67-409f-f3c0-5354722398c1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 1.7721, Train Accuracy: 69.01%\n",
            "Epoch [2/10], Train Loss: 1.6708, Train Accuracy: 79.09%\n",
            "Epoch [3/10], Train Loss: 1.6490, Train Accuracy: 81.27%\n",
            "Epoch [4/10], Train Loss: 1.6243, Train Accuracy: 83.70%\n",
            "Epoch [5/10], Train Loss: 1.6087, Train Accuracy: 85.27%\n",
            "Epoch [6/10], Train Loss: 1.6038, Train Accuracy: 85.72%\n",
            "Epoch [7/10], Train Loss: 1.6009, Train Accuracy: 86.03%\n",
            "Epoch [8/10], Train Loss: 1.5975, Train Accuracy: 86.33%\n",
            "Epoch [9/10], Train Loss: 1.5937, Train Accuracy: 86.73%\n",
            "Epoch [10/10], Train Loss: 1.5920, Train Accuracy: 86.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import intel_extension_for_pytorch as ipex\n",
        "model, optimizer = ipex.optimize(model, optimizer=optimizer)"
      ],
      "metadata": {
        "id": "BagsPY-HC5iI"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}